2018-08-22 10:17:45 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-22 10:17:45 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-22 10:17:45 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-22 10:17:45 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-22 10:17:46 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-22 10:17:46 [boto] ERROR: Unable to read instance data, giving up
2018-08-22 10:17:46 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-22 10:17:46 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-22 10:17:46 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-22 10:17:46 [scrapy] INFO: Spider opened
2018-08-22 10:17:46 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:17:55 [scrapy] INFO: Closing spider (finished)
2018-08-22 10:17:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2346,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 167798,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 22, 2, 17, 55, 504721),
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 8, 22, 2, 17, 46, 770553)}
2018-08-22 10:17:55 [scrapy] INFO: Spider closed (finished)
2018-08-22 10:18:24 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-22 10:18:24 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-22 10:18:24 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-22 10:18:24 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-22 10:18:25 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-22 10:18:25 [boto] ERROR: Unable to read instance data, giving up
2018-08-22 10:18:25 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-22 10:18:25 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-22 10:18:25 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-22 10:18:25 [scrapy] INFO: Spider opened
2018-08-22 10:18:25 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:18:26 [scrapy] INFO: Closing spider (finished)
2018-08-22 10:18:26 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2346,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 167798,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 22, 2, 18, 26, 316050),
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 8, 22, 2, 18, 25, 291228)}
2018-08-22 10:18:26 [scrapy] INFO: Spider closed (finished)
2018-08-22 10:21:10 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-22 10:21:10 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-22 10:21:10 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-22 10:21:10 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-22 10:21:11 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-22 10:21:11 [boto] ERROR: Unable to read instance data, giving up
2018-08-22 10:21:11 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-22 10:21:11 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-22 10:21:11 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-22 10:21:11 [scrapy] INFO: Spider opened
2018-08-22 10:21:11 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:21:20 [scrapy] INFO: Closing spider (finished)
2018-08-22 10:21:20 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2755,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 197637,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 22, 2, 21, 20, 266307),
 'log_count/ERROR': 2,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 7,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2018, 8, 22, 2, 21, 11, 707025)}
2018-08-22 10:21:20 [scrapy] INFO: Spider closed (finished)
2018-08-22 10:21:36 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-22 10:21:36 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-22 10:21:36 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-22 10:21:36 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-22 10:21:37 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-22 10:21:37 [boto] ERROR: Unable to read instance data, giving up
2018-08-22 10:21:37 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-22 10:21:37 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-22 10:21:37 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-22 10:21:37 [scrapy] INFO: Spider opened
2018-08-22 10:21:37 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:22:37 [scrapy] INFO: Crawled 52 pages (at 52 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:22:49 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-22 10:22:49 [scrapy] INFO: Closing spider (shutdown)
2018-08-22 10:22:54 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2018-08-22 10:24:30 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-22 10:24:30 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-22 10:24:30 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-22 10:24:30 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-22 10:24:31 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-22 10:24:31 [boto] ERROR: Unable to read instance data, giving up
2018-08-22 10:24:31 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-22 10:24:31 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-22 10:24:31 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-22 10:24:31 [scrapy] INFO: Spider opened
2018-08-22 10:24:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-22 10:25:31 [scrapy] INFO: Crawled 308 pages (at 308 pages/min), scraped 267 items (at 267 items/min)
2018-08-22 10:26:31 [scrapy] INFO: Crawled 550 pages (at 242 pages/min), scraped 473 items (at 206 items/min)
2018-08-22 10:27:31 [scrapy] INFO: Crawled 883 pages (at 333 pages/min), scraped 766 items (at 293 items/min)
2018-08-22 10:28:31 [scrapy] INFO: Crawled 1091 pages (at 208 pages/min), scraped 936 items (at 170 items/min)
2018-08-22 10:29:31 [scrapy] INFO: Crawled 1367 pages (at 276 pages/min), scraped 1171 items (at 235 items/min)
2018-08-22 10:30:31 [scrapy] INFO: Crawled 1565 pages (at 198 pages/min), scraped 1332 items (at 161 items/min)
2018-08-22 10:31:31 [scrapy] INFO: Crawled 1766 pages (at 201 pages/min), scraped 1494 items (at 162 items/min)
2018-08-22 10:32:31 [scrapy] INFO: Crawled 2030 pages (at 264 pages/min), scraped 1721 items (at 227 items/min)
2018-08-22 10:33:31 [scrapy] INFO: Crawled 2380 pages (at 350 pages/min), scraped 2039 items (at 318 items/min)
2018-08-22 10:34:31 [scrapy] INFO: Crawled 2660 pages (at 280 pages/min), scraped 2279 items (at 240 items/min)
2018-08-22 10:35:31 [scrapy] INFO: Crawled 3021 pages (at 361 pages/min), scraped 2603 items (at 324 items/min)
2018-08-22 10:36:31 [scrapy] INFO: Crawled 3245 pages (at 224 pages/min), scraped 2792 items (at 189 items/min)
2018-08-22 10:37:31 [scrapy] INFO: Crawled 3598 pages (at 353 pages/min), scraped 3105 items (at 313 items/min)
2018-08-22 10:38:31 [scrapy] INFO: Crawled 3844 pages (at 246 pages/min), scraped 3317 items (at 212 items/min)
2018-08-22 10:39:31 [scrapy] INFO: Crawled 4064 pages (at 220 pages/min), scraped 3497 items (at 180 items/min)
2018-08-22 10:40:31 [scrapy] INFO: Crawled 4286 pages (at 222 pages/min), scraped 3681 items (at 184 items/min)
2018-08-22 10:41:31 [scrapy] INFO: Crawled 4524 pages (at 238 pages/min), scraped 3880 items (at 199 items/min)
2018-08-22 10:42:31 [scrapy] INFO: Crawled 4749 pages (at 225 pages/min), scraped 4066 items (at 186 items/min)
2018-08-22 10:43:31 [scrapy] INFO: Crawled 5006 pages (at 257 pages/min), scraped 4285 items (at 219 items/min)
2018-08-22 10:43:49 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-22 10:43:49 [scrapy] INFO: Closing spider (shutdown)
2018-08-22 10:43:51 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2018-08-23 08:04:56 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-23 08:04:56 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-23 08:04:56 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-23 08:04:58 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-23 08:04:59 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-23 08:04:59 [boto] ERROR: Unable to read instance data, giving up
2018-08-23 08:04:59 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-23 08:04:59 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-23 08:04:59 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-23 08:04:59 [scrapy] INFO: Spider opened
2018-08-23 08:04:59 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-23 08:05:59 [scrapy] INFO: Crawled 416 pages (at 416 pages/min), scraped 361 items (at 361 items/min)
2018-08-23 08:06:02 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-23 08:06:02 [scrapy] INFO: Closing spider (shutdown)
2018-08-23 08:06:05 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2018-08-23 08:08:39 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-23 08:08:39 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-23 08:08:39 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-23 08:08:39 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-23 08:08:40 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-23 08:08:40 [boto] ERROR: Unable to read instance data, giving up
2018-08-23 08:08:40 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-23 08:08:40 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-23 08:08:40 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-23 08:08:40 [scrapy] INFO: Spider opened
2018-08-23 08:08:40 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-23 08:09:02 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-23 08:09:02 [scrapy] INFO: Closing spider (shutdown)
2018-08-23 08:09:03 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 209138,
 'downloader/request_count': 513,
 'downloader/request_method_count/GET': 513,
 'downloader/response_bytes': 5823036,
 'downloader/response_count': 513,
 'downloader/response_status_count/200': 513,
 'dupefilter/filtered': 719,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 8, 23, 0, 9, 3, 871958),
 'item_scraped_count': 442,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'request_depth_max': 15,
 'response_received_count': 513,
 'scheduler/dequeued': 513,
 'scheduler/dequeued/memory': 513,
 'scheduler/enqueued': 593,
 'scheduler/enqueued/memory': 593,
 'start_time': datetime.datetime(2018, 8, 23, 0, 8, 40, 436770)}
2018-08-23 08:09:03 [scrapy] INFO: Spider closed (shutdown)
2018-08-23 08:12:03 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-23 08:12:03 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-23 08:12:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-23 08:12:03 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-23 08:12:04 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-23 08:12:04 [boto] ERROR: Unable to read instance data, giving up
2018-08-23 08:12:04 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-23 08:12:04 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-23 08:12:04 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-23 08:12:04 [scrapy] INFO: Spider opened
2018-08-23 08:12:04 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-23 08:12:49 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-23 08:12:49 [scrapy] INFO: Closing spider (shutdown)
2018-08-23 08:13:01 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2018-08-23 08:24:17 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-23 08:24:17 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-23 08:24:17 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-23 08:24:17 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-23 08:24:18 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-23 08:24:18 [boto] ERROR: Unable to read instance data, giving up
2018-08-23 08:24:18 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-23 08:24:18 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-23 08:24:18 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-23 08:24:18 [scrapy] INFO: Spider opened
2018-08-23 08:24:18 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-23 08:25:18 [scrapy] INFO: Crawled 762 pages (at 762 pages/min), scraped 676 items (at 676 items/min)
2018-08-23 08:26:18 [scrapy] INFO: Crawled 1087 pages (at 325 pages/min), scraped 954 items (at 278 items/min)
2018-08-23 08:26:42 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-23 08:26:42 [scrapy] INFO: Closing spider (shutdown)
2018-08-23 08:26:47 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2018-08-23 08:29:29 [scrapy] INFO: Scrapy 1.0.3 started (bot: sundongguan)
2018-08-23 08:29:29 [scrapy] INFO: Optional features available: ssl, http11, boto
2018-08-23 08:29:29 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'sundongguan.spiders', 'SPIDER_MODULES': ['sundongguan.spiders'], 'LOG_FILE': 'sundongguan.log', 'LOG_LEVEL': 'INFO', 'BOT_NAME': 'sundongguan'}
2018-08-23 08:29:30 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2018-08-23 08:29:31 [boto] ERROR: Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 210, in retry_url
    r = opener.open(req, timeout=timeout)
  File "/usr/lib/python2.7/urllib2.py", line 429, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 447, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 407, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1228, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1198, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
2018-08-23 08:29:31 [boto] ERROR: Unable to read instance data, giving up
2018-08-23 08:29:31 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2018-08-23 08:29:31 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2018-08-23 08:29:31 [scrapy] INFO: Enabled item pipelines: SundongguanPipeline
2018-08-23 08:29:31 [scrapy] INFO: Spider opened
2018-08-23 08:29:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-23 08:29:36 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-08-23 08:29:36 [scrapy] INFO: Closing spider (shutdown)
2018-08-23 08:29:39 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
